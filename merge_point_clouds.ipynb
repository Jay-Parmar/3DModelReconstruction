{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] Read PLY failed: unable to read file: .\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd1 = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-21.ply\")\n",
    "pcd2 = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\")\n",
    "\n",
    "# pcd1_down = pcd1.voxel_down_sample(voxel_size=0.05)\n",
    "# pcd2_down = pcd2.voxel_down_sample(voxel_size=0.05)\n",
    "\n",
    "merged_pcd = pcd1 + pcd2\n",
    "\n",
    "o3d.io.write_point_cloud(\".\\Imgs\\PLYs\\Merge\\merged_cloud.ply\", merged_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "def demo_crop_geometry():\n",
    "    print(\"Demo for manual geometry cropping\")\n",
    "    print(\n",
    "        \"1) Press 'Y' twice to align geometry with negative direction of y-axis\"\n",
    "    )\n",
    "    print(\"2) Press 'K' to lock screen and to switch to selection mode\")\n",
    "    print(\"3) Drag for rectangle selection,\")\n",
    "    print(\"   or use ctrl + left click for polygon selection\")\n",
    "    print(\"4) Press 'C' to get a selected geometry\")\n",
    "    print(\"5) Press 'S' to save the selected geometry\")\n",
    "    print(\"6) Press 'F' to switch to freeview mode\")\n",
    "    pcd_data = o3d.data.DemoICPPointClouds()\n",
    "    pcd = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-21.ply\")\n",
    "    o3d.visualization.draw_geometries_with_editing([pcd])\n",
    "\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "\n",
    "def prepare_data():\n",
    "    # pcd_data = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-21.ply\")\n",
    "    target = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\")\n",
    "    print(\"Visualization of two point clouds before manual alignment\")\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "    return source, target\n",
    "\n",
    "\n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\n",
    "        \"1) Please pick at least three correspondences using [shift + left click]\"\n",
    "    )\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) After picking points, press 'Q' to close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # user picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "\n",
    "def register_via_correspondences(source, target, source_points, target_points):\n",
    "    corr = np.zeros((len(source_points), 2))\n",
    "    corr[:, 0] = source_points\n",
    "    corr[:, 1] = target_points\n",
    "    # estimate rough transformation using correspondences\n",
    "    print(\"Compute a rough transform using the correspondences given by user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(source, target,\n",
    "                                            o3d.utility.Vector2iVector(corr))\n",
    "    # point-to-point ICP for refinement\n",
    "    print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = 0.03  # 3cm distance threshold\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, threshold, trans_init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "    draw_registration_result(source, target, reg_p2p.transformation)\n",
    "\n",
    "\n",
    "def demo_manual_registration():\n",
    "    print(\"Demo for manual ICP\")\n",
    "    source, target = prepare_data()\n",
    "\n",
    "    # pick points from two point clouds and builds correspondences\n",
    "    source_points = pick_points(source)\n",
    "    target_points = pick_points(target)\n",
    "    assert (len(source_points) >= 3 and len(target_points) >= 3)\n",
    "    assert (len(source_points) == len(target_points))\n",
    "    register_via_correspondences(source, target, source_points, target_points)\n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo for manual geometry cropping\n",
      "1) Press 'Y' twice to align geometry with negative direction of y-axis\n",
      "2) Press 'K' to lock screen and to switch to selection mode\n",
      "3) Drag for rectangle selection,\n",
      "   or use ctrl + left click for polygon selection\n",
      "4) Press 'C' to get a selected geometry\n",
      "5) Press 'S' to save the selected geometry\n",
      "6) Press 'F' to switch to freeview mode\n",
      "Demo for manual ICP\n",
      "[Open3D WARNING] Read PLY failed: unable to read file: .\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\n",
      "Visualization of two point clouds before manual alignment\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #1773156 (-2.8, -1.5, -6.9) to add in queue.\n",
      "[Open3D INFO] Picked point #1723876 (-0.28, -0.79, -3.7) to add in queue.\n",
      "[Open3D INFO] Picked point #1718279 (0.019, -0.4, -1.9) to add in queue.\n",
      "\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #1792017 (-0.26, -0.74, -3.5) to add in queue.\n",
      "[Open3D INFO] Picked point #1777152 (0.59, -0.68, -3.3) to add in queue.\n",
      "[Open3D INFO] Picked point #1811929 (0.49, -0.36, -1.7) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by user\n",
      "Perform point-to-point ICP refinement\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo_crop_geometry()\n",
    "demo_manual_registration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load images\n",
    "imgL = cv2.imread('/path/to/left/image.png', 0)\n",
    "imgR = cv2.imread('/path/to/right/image.png', 0)\n",
    "\n",
    "# Camera matrices\n",
    "cameraMatrixL = np.array([[1543.48, 0, 2015.13],\n",
    "                          [0, 1541.46, 1031.24],\n",
    "                          [0, 0, 1]])\n",
    "cameraMatrixR = np.array([[1546.76, 0, 1850.32],\n",
    "                          [0, 1545.62, 989.93],\n",
    "                          [0, 0, 1]])\n",
    "\n",
    "# Distortion coefficients, assuming no lens distortion for simplification\n",
    "distCoeffsL = np.zeros(5)\n",
    "distCoeffsR = np.zeros(5)\n",
    "\n",
    "# Stereo rectify (adjust as per your calibration data)\n",
    "R = np.eye(3)  # Adjust based on actual rotation data\n",
    "T = np.array([152.854, -0.501341, 3.34597])  # Translation vector\n",
    "\n",
    "# Rectify images\n",
    "R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(cameraMatrixL, distCoeffsL, cameraMatrixR, distCoeffsR, imgL.shape[::-1], R, T)\n",
    "mapL1, mapL2 = cv2.initUndistortRectifyMap(cameraMatrixL, distCoeffsL, R1, P1, imgL.shape[::-1], cv2.CV_16SC2)\n",
    "mapR1, mapR2 = cv2.initUndistortRectifyMap(cameraMatrixR, distCoeffsR, R2, P2, imgR.shape[::-1], cv2.CV_16SC2)\n",
    "rectifiedL = cv2.remap(imgL, mapL1, mapL2, cv2.INTER_LINEAR)\n",
    "rectifiedR = cv2.remap(imgR, mapR1, mapR2, cv2.INTER_LINEAR)\n",
    "\n",
    "# Compute disparity\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(rectifiedL, rectifiedR)\n",
    "\n",
    "# Re-project to 3D\n",
    "points_3D = cv2.reprojectImageTo3D(disparity, Q)\n",
    "\n",
    "# Filter points\n",
    "mask = disparity > disparity.min()\n",
    "out_points = points_3D[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kitty Point cloudssssss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# Initialize functions\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    \"\"\"\n",
    "    param: source - source point cloud\n",
    "    param: target - target point cloud\n",
    "    param: transformation - 4 X 4 homogeneous transformation matrix\n",
    "    \"\"\"\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp], zoom=0.4459, front=[0.9288, -0.2951, -0.2242], lookat=[1.6784, 2.0612, 1.4451], up=[-0.3402, -0.9189, -0.1996])\n",
    "\n",
    "def find_nearest_neighbors(source_pc, target_pc, nearest_neigh_num):\n",
    "    # Find the closest neighbor for each anchor point through KDTree\n",
    "    point_cloud_tree = o3d.geometry.KDTreeFlann(source_pc)\n",
    "    # Find nearest target_point neighbor index\n",
    "    points_arr = []\n",
    "    for point in target_pc.points:\n",
    "        [_, idx, _] = point_cloud_tree.search_knn_vector_3d(point, nearest_neigh_num)\n",
    "        points_arr.append(source_pc.points[idx[0]])\n",
    "    return np.asarray(points_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icp(source, target):\n",
    "    source.paint_uniform_color([0.5, 0.5, 0.5])\n",
    "    target.paint_uniform_color([0, 0, 1])\n",
    "    #source_points = np.asarray(source.points) # source_points is len()=198835x3 <--> 198835 points that have (x,y,z) val\n",
    "    target_points = np.asarray(target.points)\n",
    "    # Since there are more source_points than there are target_points, we know there is not\n",
    "    # a perfect one-to-one correspondence match. Sometimes, many points will match to one point,\n",
    "    # and other times, some points may not match at all.\n",
    "\n",
    "    transform_matrix = np.asarray([[0.862, 0.011, -0.507, 0.5], [-0.139, 0.967, -0.215, 0.7], [0.487, 0.255, 0.835, -1.4], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source = source.transform(transform_matrix)\n",
    "\n",
    "    # While loop variables\n",
    "    curr_iteration = 0\n",
    "    cost_change_threshold = 1\n",
    "    curr_cost = 1000\n",
    "    prev_cost = 10000\n",
    "\n",
    "    while (True):\n",
    "        # 1. Find nearest neighbors\n",
    "        new_source_points = find_nearest_neighbors(source, target, 1)\n",
    "\n",
    "        # 2. Find point cloud centroids and their repositions\n",
    "        source_centroid = np.mean(new_source_points, axis=0)\n",
    "        target_centroid = np.mean(target_points, axis=0)\n",
    "        source_repos = np.zeros_like(new_source_points)\n",
    "        target_repos = np.zeros_like(target_points)\n",
    "        source_repos = np.asarray([new_source_points[ind] - source_centroid for ind in range(len(new_source_points))])\n",
    "        target_repos = np.asarray([target_points[ind] - target_centroid for ind in range(len(target_points))])\n",
    "\n",
    "        # 3. Find correspondence between source and target point clouds\n",
    "        cov_mat = target_repos.transpose() @ source_repos\n",
    "\n",
    "        U, X, Vt = np.linalg.svd(cov_mat)\n",
    "        R = U @ Vt\n",
    "        t = target_centroid - R @ source_centroid\n",
    "        t = np.reshape(t, (1,3))\n",
    "        curr_cost = np.linalg.norm(target_repos - (R @ source_repos.T).T)\n",
    "        print(\"Curr_cost=\", curr_cost)\n",
    "        if ((prev_cost - curr_cost) > cost_change_threshold):\n",
    "            prev_cost = curr_cost\n",
    "            transform_matrix = np.hstack((R, t.T))\n",
    "            transform_matrix = np.vstack((transform_matrix, np.array([0, 0, 0, 1])))\n",
    "            # If cost_change is acceptable, update source with new transformation matrix\n",
    "            source = source.transform(transform_matrix)\n",
    "            curr_iteration += 1\n",
    "        else:\n",
    "            break\n",
    "    print(\"\\nIteration=\", curr_iteration)\n",
    "    # Visualize final iteration and print out final variables\n",
    "    draw_registration_result(source, target, transform_matrix)\n",
    "    return transform_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr_cost= 16.78920863750992\n",
      "Curr_cost= 13.08584712859379\n",
      "Curr_cost= 11.070860691975472\n",
      "Curr_cost= 9.948424121114488\n",
      "Curr_cost= 9.213518766447848\n",
      "Curr_cost= 8.680943691549158\n",
      "Curr_cost= 8.270811369877109\n",
      "Curr_cost= 7.977670243451086\n",
      "Curr_cost= 7.78563867638042\n",
      "Curr_cost= 7.6604093757612945\n",
      "Curr_cost= 7.578429760363084\n",
      "Curr_cost= 7.524530114024888\n",
      "Curr_cost= 7.489114455798301\n",
      "Curr_cost= 7.465958777144513\n",
      "Curr_cost= 7.451037736426044\n",
      "Curr_cost= 7.441224203489374\n",
      "Curr_cost= 7.434734105682555\n",
      "Curr_cost= 7.430509492790676\n",
      "Curr_cost= 7.427687389623323\n",
      "Curr_cost= 7.425838479541511\n",
      "Curr_cost= 7.424590424353081\n",
      "Curr_cost= 7.423773127430918\n",
      "\n",
      "Iteration= 21\n"
     ]
    }
   ],
   "source": [
    "demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "part_a = icp(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] Read PLY failed: unable to read file: .\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\n",
      "std::vector<Eigen::Vector3d> with 2212577 elements.\n",
      "Use numpy.asarray() to access data. std::vector<Eigen::Vector3d> with 2274959 elements.\n",
      "Use numpy.asarray() to access data.\n",
      "Curr_cost= 2004.253240304982\n",
      "Curr_cost= 1542.4245166160804\n",
      "Curr_cost= 1321.2048211162833\n",
      "Curr_cost= 1021.2451844142612\n",
      "Curr_cost= 868.4154877176161\n",
      "Curr_cost= 821.0623051653275\n",
      "Curr_cost= 802.9714491295267\n",
      "Curr_cost= 790.4074308509959\n",
      "Curr_cost= 780.0983054806212\n",
      "Curr_cost= 770.5364059998877\n",
      "Curr_cost= 762.4868079527321\n",
      "Curr_cost= 756.7545561531053\n",
      "Curr_cost= 752.6340511504112\n",
      "Curr_cost= 749.3283819758389\n",
      "Curr_cost= 746.4677803605504\n",
      "Curr_cost= 743.933034921714\n",
      "Curr_cost= 741.7142781391289\n",
      "Curr_cost= 739.7521296135228\n",
      "Curr_cost= 737.8888094881638\n",
      "Curr_cost= 736.0400791503573\n",
      "Curr_cost= 734.2643104706368\n",
      "Curr_cost= 732.5239512472828\n",
      "Curr_cost= 730.7268867039596\n",
      "Curr_cost= 728.8978430377423\n",
      "Curr_cost= 726.8875916859187\n",
      "Curr_cost= 724.3002322569921\n",
      "Curr_cost= 721.0331178840614\n",
      "Curr_cost= 717.4061032921849\n",
      "Curr_cost= 713.4897201607573\n",
      "Curr_cost= 709.0865930491641\n",
      "Curr_cost= 704.4576317695495\n",
      "Curr_cost= 699.9230560489748\n",
      "Curr_cost= 695.5871926933067\n",
      "Curr_cost= 691.6772178868002\n",
      "Curr_cost= 688.1171543862307\n",
      "Curr_cost= 684.7653972328841\n",
      "Curr_cost= 681.1834222018696\n",
      "Curr_cost= 677.858863814855\n",
      "Curr_cost= 675.2989116363262\n",
      "Curr_cost= 673.4344301264688\n",
      "Curr_cost= 672.0591733720015\n",
      "Curr_cost= 671.0056459451314\n",
      "Curr_cost= 670.1753616463512\n",
      "\n",
      "Iteration= 42\n",
      "[Open3D WARNING] [ViewControl] SetViewPoint() failed because window height and width are not set.\n"
     ]
    }
   ],
   "source": [
    "source = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-21.ply\")\n",
    "target = o3d.io.read_point_cloud(\".\\Imgs\\PLYs\\Merge\\point_cloud_PLY_107761722_1200_13-09-2024-16-25-35.ply\")\n",
    "print(source.points, target.points)\n",
    "part_b = icp(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneighbors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NearestNeighbors\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_fit_transform\u001b[39m(A, B):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    Calculates the least-squares best-fit transform that maps corresponding points A to B in m spatial dimensions\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m    Input:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m      t: mx1 translation vector\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def best_fit_transform(A, B):\n",
    "    '''\n",
    "    Calculates the least-squares best-fit transform that maps corresponding points A to B in m spatial dimensions\n",
    "    Input:\n",
    "      A: Nxm numpy array of corresponding points\n",
    "      B: Nxm numpy array of corresponding points\n",
    "    Returns:\n",
    "      T: (m+1)x(m+1) homogeneous transformation matrix that maps A on to B\n",
    "      R: mxm rotation matrix\n",
    "      t: mx1 translation vector\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # translate points to their centroids\n",
    "    centroid_A = np.mean(A, axis=0)\n",
    "    centroid_B = np.mean(B, axis=0)\n",
    "    AA = A - centroid_A\n",
    "    BB = B - centroid_B\n",
    "\n",
    "    # rotation matrix\n",
    "    H = np.dot(AA.T, BB)\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # special reflection case\n",
    "    if np.linalg.det(R) < 0:\n",
    "       Vt[m-1,:] *= -1\n",
    "       R = np.dot(Vt.T, U.T)\n",
    "\n",
    "    # translation\n",
    "    t = centroid_B.T - np.dot(R,centroid_A.T)\n",
    "\n",
    "    # homogeneous transformation\n",
    "    T = np.identity(m+1)\n",
    "    T[:m, :m] = R\n",
    "    T[:m, m] = t\n",
    "\n",
    "    return T, R, t\n",
    "\n",
    "\n",
    "def nearest_neighbor(src, dst):\n",
    "    '''\n",
    "    Find the nearest (Euclidean) neighbor in dst for each point in src\n",
    "    Input:\n",
    "        src: Nxm array of points\n",
    "        dst: Nxm array of points\n",
    "    Output:\n",
    "        distances: Euclidean distances of the nearest neighbor\n",
    "        indices: dst indices of the nearest neighbor\n",
    "    '''\n",
    "\n",
    "    assert src.shape == dst.shape\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors=1)\n",
    "    neigh.fit(dst)\n",
    "    distances, indices = neigh.kneighbors(src, return_distance=True)\n",
    "    return distances.ravel(), indices.ravel()\n",
    "\n",
    "\n",
    "def icp(A, B, init_pose=None, max_iterations=20, tolerance=0.001):\n",
    "    '''\n",
    "    The Iterative Closest Point method: finds best-fit transform that maps points A on to points B\n",
    "    Input:\n",
    "        A: Nxm numpy array of source mD points\n",
    "        B: Nxm numpy array of destination mD point\n",
    "        init_pose: (m+1)x(m+1) homogeneous transformation\n",
    "        max_iterations: exit algorithm after max_iterations\n",
    "        tolerance: convergence criteria\n",
    "    Output:\n",
    "        T: final homogeneous transformation that maps A on to B\n",
    "        distances: Euclidean distances (errors) of the nearest neighbor\n",
    "        i: number of iterations to converge\n",
    "    '''\n",
    "\n",
    "    assert A.shape == B.shape\n",
    "\n",
    "    # get number of dimensions\n",
    "    m = A.shape[1]\n",
    "\n",
    "    # make points homogeneous, copy them to maintain the originals\n",
    "    src = np.ones((m+1,A.shape[0]))\n",
    "    dst = np.ones((m+1,B.shape[0]))\n",
    "    src[:m,:] = np.copy(A.T)\n",
    "    dst[:m,:] = np.copy(B.T)\n",
    "\n",
    "    # apply the initial pose estimation\n",
    "    if init_pose is not None:\n",
    "        src = np.dot(init_pose, src)\n",
    "\n",
    "    prev_error = 0\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        # find the nearest neighbors between the current source and destination points\n",
    "        distances, indices = nearest_neighbor(src[:m,:].T, dst[:m,:].T)\n",
    "\n",
    "        # compute the transformation between the current source and nearest destination points\n",
    "        T,_,_ = best_fit_transform(src[:m,:].T, dst[:m,indices].T)\n",
    "\n",
    "        # update the current source\n",
    "        src = np.dot(T, src)\n",
    "\n",
    "        # check error\n",
    "        mean_error = np.mean(distances)\n",
    "        if np.abs(prev_error - mean_error) < tolerance:\n",
    "            break\n",
    "        prev_error = mean_error\n",
    "\n",
    "    # calculate final transformation\n",
    "    T,_,_ = best_fit_transform(A, src[:m,:].T)\n",
    "\n",
    "    return T, distances, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def Reprojection3D(image, disparity, f, b):\n",
    "    # Camera parameters\n",
    "    cx = 1007.56  # principal point x from LEFT_CAM_FHD\n",
    "    cy = 515.619  # principal point y from LEFT_CAM_FHD\n",
    "\n",
    "    # Creating the Q matrix with updated values\n",
    "    Q = np.array([\n",
    "        [1, 0, 0, -cx],\n",
    "        [0, 1, 0, -cy],\n",
    "        [0, 0, 0, f],\n",
    "        [0, 0, -1/b, 0]\n",
    "    ])\n",
    "\n",
    "    if disparity.dtype != np.float32:\n",
    "        disparity = disparity.astype(np.float32)\n",
    "    \n",
    "    if image.dtype != np.float32:\n",
    "        image = image.astype(np.float32)\n",
    "\n",
    "    # Reprojecting to 3D\n",
    "    points = cv2.reprojectImageTo3D(disparity, Q)\n",
    "    mask = disparity > disparity.min()\n",
    "    out_points = points[mask]\n",
    "    out_colors = image[mask]\n",
    "    verts = out_points.reshape(-1, 3)\n",
    "    colors = out_colors.reshape(-1, 3).astype(np.uint8)\n",
    "    verts = np.hstack([verts, colors])\n",
    "\n",
    "    # Preparing to save in PLY format\n",
    "    ply_header = '''ply\n",
    "format ascii 1.0\n",
    "element vertex %(vert_num)d\n",
    "property float x\n",
    "property float y\n",
    "property float z\n",
    "property uchar blue\n",
    "property uchar green\n",
    "property uchar red\n",
    "end_header\n",
    "'''\n",
    "    with open('zed_stereo.ply', 'w') as f:\n",
    "        f.write(ply_header % dict(vert_num=len(verts)))\n",
    "        np.savetxt(f, verts, '%f %f %f %d %d %d')\n",
    "\n",
    "# Assume f is the average of fx and fy from LEFT_CAM_FHD\n",
    "f = (771.738 + 770.73) / 2\n",
    "b = 152.854  # Baseline in mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "disp = cv2.imread('.\\Imgs\\PLYs\\Merge\\DepthViewer_depthimage_107761722_1200_14-09-2024-12-27-53.png', cv2.IMREAD_GRAYSCALE )\n",
    "imgg = cv2.imread('.\\Imgs\\PLYs\\Merge\\DepthViewer_Left_107761722_1200_14-09-2024-12-27-40.png')\n",
    "Reprojection3D(imgg, disp, f, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
